{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73233,"databundleVersionId":8112053,"sourceType":"competition"}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport pickle\n\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        batch = pickle.load(fo, encoding='bytes')\n    return batch\n\n# Specify the folder where the CIFAR-10 batch files are\ncifar10_dir = '/kaggle/input/deep-learning-mini-project-spring-24-nyu/cifar-10-python/cifar-10-batches-py'\n\n\n# Load the batch \nvalidation_batch = load_cifar_batch('/kaggle/input/deep-learning-mini-project-spring-24-nyu/cifar-10-python/cifar-10-batches-py/test_batch')\n# Load the label names\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = meta_data_dict[b'label_names']\n\n\ndef load_cifar10_batches(cifar10_dir, batch_ids):\n    images = []\n    labels = []\n    \n    for batch_id in batch_ids:\n        batch_path = os.path.join(cifar10_dir, f'data_batch_{batch_id}')\n        with open(batch_path, 'rb') as file:\n            batch = pickle.load(file, encoding='bytes')\n            img = batch[b'data'].reshape((-1, 3, 32, 32)).transpose(0, 2, 3, 1)\n            lb = batch[b'labels']\n            plt.figure(figsize=(10, 10))  # Adjusted figure size for better visibility\n            for i in range(10):  # Loop through the first 100 images\n                plt.subplot(1, 10, i + 1)  # Arrange plots in 10x10 grid\n                plt.imshow(img[i+10])\n                plt.title(label_names[lb[i+10]].decode('utf-8'), fontsize=10)  # Ensure title is small enough to fit\n                plt.axis('off')\n            plt.tight_layout()  # Adjust subplots to fit in the figure area\n            plt.show()\n            \n            images.append(batch[b'data'])\n            labels.append(batch[b'labels'])\n    \n    images = np.concatenate(images).reshape((-1, 3, 32, 32)).transpose(0, 2, 3, 1)\n    #print(type(images))\n    #print(images.shape)\n    #images = images.astype('float32')\n    labels = np.concatenate(labels)\n    \n    return images, labels\n\n\n\ntrain_images, train_labels = load_cifar10_batches(cifar10_dir, range(1, 6))\nvalidation_images = validation_batch[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)#.astype('float32')\nvalidation_labels = validation_batch[b'labels']\nprint(train_images.shape)\nprint(len(train_labels))\n#print(validation_images[0])\n#print(train_images[0])\nimport numpy as np\n\n# Concatenate the training and validation images\ntrain_images = np.concatenate((train_images, validation_images), axis=0)\n\n# Concatenate the training and validation labels\ntrain_labels = np.concatenate((train_labels, validation_labels), axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:44:38.549469Z","iopub.execute_input":"2024-04-11T15:44:38.550389Z","iopub.status.idle":"2024-04-11T15:44:42.501869Z","shell.execute_reply.started":"2024-04-11T15:44:38.550350Z","shell.execute_reply":"2024-04-11T15:44:42.500858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the test file, note that it has no labels and needs to be used with your model inference to predict outputs.\n\n# Load the batch \ntest_batch = load_cifar_batch('/kaggle/input/deep-learning-mini-project-spring-24-nyu/cifar_test_nolabels.pkl')\n\n# Extract images\nimages = test_batch[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1) \n\n\n\nplt.figure(figsize=(20, 4))\nfor i in range(10):\n    plt.subplot(1, 10, i+1)\n    plt.imshow(images[i])\n    plt.axis('off')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-11T15:44:42.504285Z","iopub.execute_input":"2024-04-11T15:44:42.504951Z","iopub.status.idle":"2024-04-11T15:44:42.959637Z","shell.execute_reply.started":"2024-04-11T15:44:42.504912Z","shell.execute_reply":"2024-04-11T15:44:42.958379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass ImageDataset(Dataset):\n    def __init__(self, images, labels = None, transform=None,test=False,gan = False):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        \n        super().__init__()\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n        self.test = test\n        self.gan = gan\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx];\n\n        if self.transform:\n            image = self.transform(image=image)['image']\n            \n        if self.gan:\n            return image, 1\n            \n        if self.test:\n            return image\n        \n        label = self.labels[idx]\n        \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:44:42.961393Z","iopub.execute_input":"2024-04-11T15:44:42.961983Z","iopub.status.idle":"2024-04-11T15:44:44.773290Z","shell.execute_reply.started":"2024-04-11T15:44:42.961956Z","shell.execute_reply":"2024-04-11T15:44:44.772478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\ntransforms_train = albumentations.Compose(\n    [\n\n        albumentations.Resize(64, 64),\n        albumentations.HorizontalFlip(p=0.5),\n        #albumentations.VerticalFlip(p=0.5),\n        albumentations.Rotate(limit=45, p=0.5),\n        albumentations.RandomBrightnessContrast(brightness_limit=(-0.5, 0.5), contrast_limit=(-0.5, 0.5), p=0.5),\n        albumentations.ShiftScaleRotate(\n            shift_limit=0.2, scale_limit=(-0.2,0.5), rotate_limit=0\n        ),\n        albumentations.Normalize(\n            [0.4914, 0.4822, 0.4465],[0.247, 0.243, 0.261],\n            max_pixel_value=255.0, always_apply=True\n        ),\n        ToTensorV2(p=1.0),\n    ]\n)\n\ntransforms_test = albumentations.Compose(\n        [\n            albumentations.Resize(64, 64),\n            #albumentations.Resize(144, 144),\n            albumentations.Normalize(\n                [0.4914, 0.4822, 0.4465],[0.247, 0.243, 0.261],\n                max_pixel_value=255.0, always_apply=True\n            ),\n            ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:44:44.774435Z","iopub.execute_input":"2024-04-11T15:44:44.774824Z","iopub.status.idle":"2024-04-11T15:44:45.505918Z","shell.execute_reply.started":"2024-04-11T15:44:44.774798Z","shell.execute_reply":"2024-04-11T15:44:45.505079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.datasets \nimport torchvision.transforms as transforms\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts,ExponentialLR\n# net = torchvision.models.resnet18()\n# in_features = net.fc.in_features\n# net.fc = nn.Linear(in_features, 10)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:44:45.509170Z","iopub.execute_input":"2024-04-11T15:44:45.509946Z","iopub.status.idle":"2024-04-11T15:44:46.937055Z","shell.execute_reply.started":"2024-04-11T15:44:45.509916Z","shell.execute_reply":"2024-04-11T15:44:46.936253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torchvision import transforms, datasets\nimport torch.optim as optim\n\n\nclass ResBlock(nn.Module):\n    def __init__(self, in_features):\n        super(ResBlock, self).__init__()\n        self.block = nn.Sequential(\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.BatchNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.BatchNorm2d(in_features)\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\nclass Generator(nn.Module):\n    def __init__(self, input_channels=3, num_residual_blocks=2):\n        super(Generator, self).__init__()\n        self.initial = nn.Sequential(\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(input_channels, 16, 7),\n            nn.BatchNorm2d(16),\n            nn.ReLU(inplace=True)\n        )\n\n        # Downsample\n        self.downsample = nn.Sequential(\n            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 96, 3, stride=2, padding=1),\n            nn.BatchNorm2d(96),\n            nn.ReLU(inplace=True)\n        )\n\n        # Residual blocks\n        self.resblocks = nn.Sequential(\n            *[ResBlock(96) for _ in range(num_residual_blocks)]\n        )\n\n        # Upsample\n        self.upsample = nn.Sequential(\n            nn.ConvTranspose2d(96, 32, 3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(inplace=True)\n        )\n\n        # Output layer\n        self.output = nn.Sequential(\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(16, input_channels, 7),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        x = self.initial(x)\n        x = self.downsample(x)\n        x = self.resblocks(x)\n        x = self.upsample(x)\n        x = self.output(x)\n        return x\n\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(3, 4, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(4, 8, 4, stride=2, padding=1),\n            nn.BatchNorm2d(8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(8, 1, 4, stride=1, padding=0),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.main(input)\n\n    # Initialize networks\nG_A2B = Generator()\nG_B2A = Generator()\nD_A = Discriminator()\nD_B = Discriminator()\n\n# Losses\ncriterion_GAN = nn.MSELoss()\ncriterion_cycle = nn.L1Loss()\n\n# Optimizers\noptimizer_G = optim.Adam(list(G_A2B.parameters()) + list(G_B2A.parameters()), lr=0.0002, betas=(0.5, 0.999))\noptimizer_D_A = optim.Adam(D_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizer_D_B = optim.Adam(D_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:44:46.938592Z","iopub.execute_input":"2024-04-11T15:44:46.939181Z","iopub.status.idle":"2024-04-11T15:44:46.978273Z","shell.execute_reply.started":"2024-04-11T15:44:46.939155Z","shell.execute_reply":"2024-04-11T15:44:46.977489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nG_A2B = G_A2B.to(device)\nG_B2A = G_B2A.to(device)\nD_A = D_A.to(device)\nD_B = D_B.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:44:46.979196Z","iopub.execute_input":"2024-04-11T15:44:46.979466Z","iopub.status.idle":"2024-04-11T15:44:47.108708Z","shell.execute_reply.started":"2024-04-11T15:44:46.979443Z","shell.execute_reply":"2024-04-11T15:44:47.107886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loader_A = ImageDataset(validation_images, train_labels,transform = transforms_test)\n\nloader_B = ImageDataset(images, gan = True, transform = transforms_test )\n\nloader_A = DataLoader(loader_A, batch_size=64, shuffle=True, drop_last=False)\nloader_B = DataLoader(loader_B, batch_size=64, shuffle=True, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:44:47.109875Z","iopub.execute_input":"2024-04-11T15:44:47.110170Z","iopub.status.idle":"2024-04-11T15:44:47.116240Z","shell.execute_reply.started":"2024-04-11T15:44:47.110145Z","shell.execute_reply":"2024-04-11T15:44:47.115276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Assuming 'loader_A' and 'loader_B' are your DataLoader instances for domain A and B.\n# Number of epochs\nn_epochs = 40\n\n# Lambda terms for cycle and identity loss\nlambda_cycle = 5.0\nlambda_identity = 1.0\nfrom tqdm.auto import tqdm\nfor epoch in range(n_epochs):\n    for batch_A, batch_B in tqdm(zip(loader_A, loader_B)):\n        real_A = batch_A[0].to(device)\n        real_B = batch_B[0].to(device)\n\n        ###### Generators A2B and B2A ######\n        optimizer_G.zero_grad()\n\n        # Identity loss\n        same_B = G_A2B(real_B)\n        loss_identity_B = criterion_cycle(same_B, real_B) * lambda_identity\n        same_A = G_B2A(real_A)\n        loss_identity_A = criterion_cycle(same_A, real_A) * lambda_identity\n\n        # GAN loss\n        fake_B = G_A2B(real_A)\n        pred_fake = D_B(fake_B)\n        loss_GAN_A2B = criterion_GAN(pred_fake, torch.ones_like(pred_fake))\n\n        fake_A = G_B2A(real_B)\n        pred_fake = D_A(fake_A)\n        loss_GAN_B2A = criterion_GAN(pred_fake, torch.ones_like(pred_fake))\n\n        # Cycle loss\n        recovered_A = G_B2A(fake_B)\n        loss_cycle_ABA = criterion_cycle(recovered_A, real_A) * lambda_cycle\n\n        recovered_B = G_A2B(fake_A)\n        loss_cycle_BAB = criterion_cycle(recovered_B, real_B) * lambda_cycle\n\n        # Total loss\n        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n        loss_G.backward()\n        optimizer_G.step()\n\n        ###### Discriminator A ######\n        optimizer_D_A.zero_grad()\n\n        # Real loss\n        pred_real = D_A(real_A)\n        loss_D_real = criterion_GAN(pred_real, torch.ones_like(pred_real))\n\n        # Fake loss\n        pred_fake = D_A(fake_A.detach())\n        loss_D_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake))\n\n        # Total loss\n        loss_D_A = (loss_D_real + loss_D_fake) * 0.5\n        loss_D_A.backward()\n        optimizer_D_A.step()\n\n        ###### Discriminator B ######\n        optimizer_D_B.zero_grad()\n\n        # Real loss\n        pred_real = D_B(real_B)\n        loss_D_real = criterion_GAN(pred_real, torch.ones_like(pred_real))\n\n        # Fake loss\n        pred_fake = D_B(fake_B.detach())\n        loss_D_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake))\n\n        # Total loss\n        loss_D_B = (loss_D_real + loss_D_fake) * 0.5\n        loss_D_B.backward()\n        optimizer_D_B.step()\n\n    print(f\"Epoch {epoch}/{n_epochs} finished\")\n    print(f\"Loss G: {loss_G.item():.4f}, \"\n          f\"Loss D_X: {loss_D_A.item():.4f}, Loss D_Y: {loss_D_B.item():.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:44:47.117666Z","iopub.execute_input":"2024-04-11T15:44:47.118436Z","iopub.status.idle":"2024-04-11T15:46:47.514005Z","shell.execute_reply.started":"2024-04-11T15:44:47.118402Z","shell.execute_reply":"2024-04-11T15:46:47.511073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\n\ndef visualize_cycleGAN_results(model_G_A2B, model_G_B2A, test_loader_A, test_loader_B):\n    # Switch models to evaluation mode\n    model_G_A2B.eval()\n    model_G_B2A.eval()\n    count = 0\n    with torch.no_grad(): # No need to track gradients\n        for batchA,batchB in zip(test_loader_A,test_loader_B):\n            real_A, _ = batchA\n            real_B, _ = batchB\n            real_A = real_A.to(device)\n            real_B = real_B.to(device)\n            count+=1;\n            \n            # Generate images from domain A to B and back to A\n            fake_A = model_G_A2B(real_A)\n            fake_B = model_G_B2A(real_B)\n            \n            # Move images back to CPU for visualization\n            real_A = real_A.cpu()\n            real_B = real_B.cpu()\n            fake_A = fake_A.cpu()\n            fake_B = fake_B.cpu()\n\n            # Plot the original, transformed, and reconstructed images\n            plt.figure(figsize=(6, 3))\n            \n            # Display real image\n            plt.subplot(2, 2, 1)\n            plt.title(\"Original Image A\")\n            plt.imshow(real_A[0].permute(1, 2, 0).numpy() * 0.5 + 0.5) # Unnormalize\n            plt.axis('off')\n            \n             # Display real image\n            plt.subplot(2, 2, 2)\n            plt.title(\"Fake A\")\n            plt.imshow(fake_A[0].permute(1, 2, 0).numpy() * 0.5 + 0.5) # Unnormalize\n            plt.axis('off')\n            \n            # Display real image\n            plt.subplot(2, 2, 3)\n            plt.title(\"Original Image B\")\n            plt.imshow(real_B[0].permute(1, 2, 0).numpy() * 0.5 + 0.5) # Unnormalize\n            plt.axis('off')\n            \n             # Display real image\n            plt.subplot(2, 2, 4)\n            plt.title(\"Fake B\")\n            plt.imshow(fake_B[0].permute(1, 2, 0).numpy() * 0.5 + 0.5) # Unnormalize\n            plt.axis('off')\n\n            plt.show()\n            if count == 10:\n                break # Just show one set of images for example\n\n# Assuming model_G_A2B, model_G_B2A, and test_loader_A are defined and loaded\nvisualize_cycleGAN_results(G_A2B, G_B2A, loader_A,loader_B)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:46:51.949421Z","iopub.execute_input":"2024-04-11T15:46:51.949826Z","iopub.status.idle":"2024-04-11T15:46:55.099782Z","shell.execute_reply.started":"2024-04-11T15:46:51.949796Z","shell.execute_reply":"2024-04-11T15:46:55.098769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G_A2B.eval()\nG_B2A.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:12.436437Z","iopub.execute_input":"2024-04-11T15:47:12.437524Z","iopub.status.idle":"2024-04-11T15:47:12.444621Z","shell.execute_reply.started":"2024-04-11T15:47:12.437487Z","shell.execute_reply":"2024-04-11T15:47:12.443700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass Root(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=1):\n        super(Root, self).__init__()\n        self.conv = nn.Conv2d(\n            in_channels, out_channels, kernel_size,\n            stride=1, padding=(kernel_size - 1) // 2, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n\n    def forward(self, xs):\n        x = torch.cat(xs, 1)\n        out = F.relu(self.bn(self.conv(x)))\n        return out\n\n\nclass Tree(nn.Module):\n    def __init__(self, block, in_channels, out_channels, level=1, stride=1):\n        super(Tree, self).__init__()\n        self.level = level\n        if level == 1:\n            self.root = Root(2*out_channels, out_channels)\n            self.left_node = block(in_channels, out_channels, stride=stride)\n            self.right_node = block(out_channels, out_channels, stride=1)\n        else:\n            self.root = Root((level+2)*out_channels, out_channels)\n            for i in reversed(range(1, level)):\n                subtree = Tree(block, in_channels, out_channels,\n                               level=i, stride=stride)\n                self.__setattr__('level_%d' % i, subtree)\n            self.prev_root = block(in_channels, out_channels, stride=stride)\n            self.left_node = block(out_channels, out_channels, stride=1)\n            self.right_node = block(out_channels, out_channels, stride=1)\n\n    def forward(self, x):\n        xs = [self.prev_root(x)] if self.level > 1 else []\n        for i in reversed(range(1, self.level)):\n            level_i = self.__getattr__('level_%d' % i)\n            x = level_i(x)\n            xs.append(x)\n        x = self.left_node(x)\n        xs.append(x)\n        x = self.right_node(x)\n        xs.append(x)\n        out = self.root(xs)\n        return out\n\n\nclass DLA(nn.Module):\n    def __init__(self, block=BasicBlock, num_classes=10):\n        super(DLA, self).__init__()\n        self.base = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(16),\n            nn.ReLU(True)\n        )\n\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(16),\n            nn.ReLU(True)\n        )\n\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(True)\n        )\n        \n        \n\n        self.layer3 = Tree(block,  32,  64, level=1, stride=2)\n        self.layer4 = Tree(block,  64, 128, level=2, stride=2)\n        self.layer5 = Tree(block, 128, 256, level=1, stride=2)\n#         self.layer6 = nn.Sequential(\n#             nn.Conv2d(256, 512, kernel_size=2, stride=2, bias=False),\n#             nn.BatchNorm2d(512),\n#             nn.ReLU(True)\n#         )\n        #self.layer6 = Tree(block, 256, 512, level=1, stride=2)\n        self.linear = nn.Linear(1024, num_classes)\n\n    def forward(self, x):\n        out = self.base(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        #out = self.layer6(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\n\n\n\nnet = DLA()","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:15.557891Z","iopub.execute_input":"2024-04-11T15:47:15.558296Z","iopub.status.idle":"2024-04-11T15:47:15.625277Z","shell.execute_reply.started":"2024-04-11T15:47:15.558262Z","shell.execute_reply":"2024-04-11T15:47:15.624354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\nparent = timm.create_model('dla102', pretrained=False,num_classes=10)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:17.220364Z","iopub.execute_input":"2024-04-11T15:47:17.221050Z","iopub.status.idle":"2024-04-11T15:47:18.871249Z","shell.execute_reply.started":"2024-04-11T15:47:17.221014Z","shell.execute_reply":"2024-04-11T15:47:18.870242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install torch-summary","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:20.380333Z","iopub.execute_input":"2024-04-11T15:47:20.381422Z","iopub.status.idle":"2024-04-11T15:47:20.385678Z","shell.execute_reply.started":"2024-04-11T15:47:20.381380Z","shell.execute_reply":"2024-04-11T15:47:20.384789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torchsummary import summary\n# summary(model, (3, 64, 64))","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:20.639596Z","iopub.execute_input":"2024-04-11T15:47:20.639895Z","iopub.status.idle":"2024-04-11T15:47:20.643956Z","shell.execute_reply.started":"2024-04-11T15:47:20.639872Z","shell.execute_reply":"2024-04-11T15:47:20.642917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnet  = net.to(device)\nparent = parent.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:22.755696Z","iopub.execute_input":"2024-04-11T15:47:22.756069Z","iopub.status.idle":"2024-04-11T15:47:22.824579Z","shell.execute_reply.started":"2024-04-11T15:47:22.756037Z","shell.execute_reply":"2024-04-11T15:47:22.823620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef train_model(train_loader):\n    losses = []\n    optimizer = optim.Adam(net.parameters(), lr=0.0002,weight_decay=1e-5)\n    loss = nn.CrossEntropyLoss(reduction='mean')\n#     scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min = 1e-6)\n    scheduler = ExponentialLR(optimizer, gamma=0.975,verbose=True)\n    for i in range(epoch):\n        acc = 0\n        loss_sum = 0\n        net.train()\n        for x, y in tqdm(train_loader):\n            x = x.to(device)\n            #print(x.shape)\n            num = torch.rand(1).item()\n            if num>=0 and num<0.3:\n                x = G_A2B(x)\n            x = torch.as_tensor(x, dtype=torch.float)\n            y = y.to(device)\n            #print(y.shape)\n            #print(y)\n            y_hat = net(x)\n            #print(y_hat.shape)\n            #print(y_hat)\n            #print(y_hat.argmax(dim=1).type(y.dtype))\n            loss_temp = loss(y_hat, y)\n            loss_sum += loss_temp\n            optimizer.zero_grad()\n            loss_temp.backward()\n            optimizer.step()\n#             scheduler.step()\n            acc += torch.sum(y_hat.argmax(dim=1).type(y.dtype) == y)\n        scheduler.step()\n        losses.append(loss_sum.cpu().detach().numpy() / len(train_loader))\n        print( \"epoch: \", i, \"loss=\", loss_sum.item(), \"训练集准确度=\",(acc/(len(train_loader)*train_loader.batch_size)).item(),end=\"\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:23.052549Z","iopub.execute_input":"2024-04-11T15:47:23.052935Z","iopub.status.idle":"2024-04-11T15:47:23.063585Z","shell.execute_reply.started":"2024-04-11T15:47:23.052902Z","shell.execute_reply":"2024-04-11T15:47:23.062529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef train_parent(train_loader):\n    losses = []\n    optimizer = optim.Adam(parent.parameters(), lr=0.00007,weight_decay=1e-5)\n    loss = nn.CrossEntropyLoss(reduction='mean')\n#     scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min = 1e-6)\n    scheduler = ExponentialLR(optimizer, gamma=0.975,verbose=True)\n    for i in range(epoch):\n        acc = 0\n        loss_sum = 0\n        parent.train()\n        for x, y in tqdm(train_loader):\n            x = x.to(device)\n            #print(x.shape)\n            num = torch.rand(1).item()\n            if num>=0 and num<0.3:\n                x = G_A2B(x)\n            x = torch.as_tensor(x, dtype=torch.float)\n            y = y.to(device)\n            #print(y.shape)\n            #print(y)\n            y_hat = parent(x)\n            #print(y_hat.shape)\n            #print(y_hat)\n            #print(y_hat.argmax(dim=1).type(y.dtype))\n            loss_temp = loss(y_hat, y)\n            loss_sum += loss_temp\n            optimizer.zero_grad()\n            loss_temp.backward()\n            optimizer.step()\n#             scheduler.step()\n            acc += torch.sum(y_hat.argmax(dim=1).type(y.dtype) == y)\n        scheduler.step()\n        losses.append(loss_sum.cpu().detach().numpy() / len(train_loader))\n        print( \"epoch: \", i, \"loss=\", loss_sum.item(), \"训练集准确度=\",(acc/(len(train_loader)*train_loader.batch_size)).item(),end=\"\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:23.552531Z","iopub.execute_input":"2024-04-11T15:47:23.552948Z","iopub.status.idle":"2024-04-11T15:47:23.563721Z","shell.execute_reply.started":"2024-04-11T15:47:23.552913Z","shell.execute_reply":"2024-04-11T15:47:23.562721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class DistillationLoss(nn.Module):\n#     def __init__(self, temperature=1):\n#         super(DistillationLoss, self).__init__()\n#         self.temperature = temperature\n\n#     def forward(self, outputs_student, outputs_teacher):\n#         soft_targets = nn.functional.softmax(outputs_teacher / self.temperature, dim=1)\n#         log_probs = nn.functional.log_softmax(outputs_student / self.temperature, dim=1)\n#         return nn.KLDivLoss(reduction='batchmean')(log_probs, soft_targets)\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DistillationLoss(nn.Module):\n    def __init__(self, temperature=1.0, alpha=0.5):\n        \"\"\"\n        :param temperature: Temperature parameter to soften probability distributions.\n        :param alpha: Weighting factor for the distillation loss vs. the standard loss.\n        \"\"\"\n        super(DistillationLoss, self).__init__()\n        self.temperature = temperature\n        self.alpha = alpha\n        self.kl_div = nn.KLDivLoss(reduction='batchmean')\n\n    def forward(self, outputs_student, outputs_teacher, labels=None):\n        \"\"\"\n        Compute the distillation loss between the student and teacher outputs.\n        If labels are provided, also compute the standard loss and return a weighted sum.\n        \"\"\"\n        soft_targets = F.softmax(outputs_teacher / self.temperature, dim=1)\n        log_probs = F.log_softmax(outputs_student / self.temperature, dim=1)\n        distillation_loss = self.kl_div(log_probs, soft_targets)\n        \n        if labels is not None:\n            standard_loss = F.cross_entropy(outputs_student, labels)\n            return self.alpha * standard_loss + (1 - self.alpha) * distillation_loss\n        else:\n            return distillation_loss\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:23.975692Z","iopub.execute_input":"2024-04-11T15:47:23.976646Z","iopub.status.idle":"2024-04-11T15:47:23.985560Z","shell.execute_reply.started":"2024-04-11T15:47:23.976609Z","shell.execute_reply":"2024-04-11T15:47:23.984538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef train_model_with_teacher(train_loader):\n    losses = []\n    optimizer = optim.Adam(net.parameters(), lr=0.0006,weight_decay=1e-5)\n    loss = nn.CrossEntropyLoss(reduction='mean')\n    distillation_loss = DistillationLoss(temperature=3) \n#     scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min = 1e-6)\n    scheduler = ExponentialLR(optimizer, gamma=0.975,verbose=True)\n    for i in range(epoch):\n        acc = 0\n        loss_sum = 0\n        net.train()\n        for x, y in tqdm(train_loader):\n            x = x.to(device)\n            #print(x.shape)\n            num = torch.rand(1).item()\n            if num>=0 and num<0.3:\n                x = G_A2B(x)\n            x = torch.as_tensor(x, dtype=torch.float)\n            y = y.to(device)  \n            y_hat = net(x)\n            \n            outputs_teacher = parent(x)\n            outputs_student = net(x)\n            \n            loss_temp = loss(outputs_student, y) + distillation_loss(outputs_student, outputs_teacher)\n            \n            loss_sum += loss_temp\n            optimizer.zero_grad()\n            loss_temp.backward()\n            optimizer.step()\n#             scheduler.step()\n            acc += torch.sum(y_hat.argmax(dim=1).type(y.dtype) == y)\n        scheduler.step()\n        losses.append(loss_sum.cpu().detach().numpy() / len(train_loader))\n        print( \"epoch: \", i, \"loss=\", loss_sum.item(), \"训练集准确度=\",(acc/(len(train_loader)*train_loader.batch_size)).item(),end=\"\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:24.385606Z","iopub.execute_input":"2024-04-11T15:47:24.386240Z","iopub.status.idle":"2024-04-11T15:47:24.396863Z","shell.execute_reply.started":"2024-04-11T15:47:24.386202Z","shell.execute_reply":"2024-04-11T15:47:24.395937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef teach_student(train_loader):\n    losses = []\n    optimizer = optim.Adam(net.parameters(), lr=0.0003,weight_decay=1e-5)\n    teacher_optimizer = optim.Adam(parent.parameters(), lr=0.00003,weight_decay=1e-5)\n    student_optimizer = optim.Adam(net.parameters(), lr=0.001,weight_decay=1e-5)\n    loss = nn.CrossEntropyLoss(reduction='mean')\n    distillation_loss = DistillationLoss(temperature=3) \n    scheduler = ExponentialLR(teacher_optimizer, gamma=0.99,verbose=True)\n    scheduler = ExponentialLR(student_optimizer, gamma=0.98,verbose=True)\n    for i in range(epoch):\n        acc = 0\n        acc_t = 0\n        loss_sum = 0\n        net.train()\n        parent.train()\n        for x, y in tqdm(train_loader):\n            teacher_optimizer.zero_grad()\n            student_optimizer.zero_grad()\n            x = x.to(device)\n            #print(x.shape)\n            x = torch.as_tensor(x, dtype=torch.float)\n            y = y.to(device)\n            \n            outputs_teacher = parent(x)\n            outputs_student = net(x)\n            \n            loss_teacher = loss(outputs_teacher, y)\n            loss_student = loss(outputs_student, y) + distillation_loss(outputs_student, outputs_teacher)\n#             print(\"loss\")\n#             print(loss(outputs_student, y))\n#             print(distillation_loss(outputs_student, outputs_teacher))\n#             print(outputs_teacher)\n#             print(outputs_student)\n            \n            loss_sum += loss_teacher\n\n            loss_teacher.backward(retain_graph=True)\n#             loss_teacher.backward()\n            loss_student.backward()\n            teacher_optimizer.step()\n            student_optimizer.step()\n            \n            acc += torch.sum(outputs_student.argmax(dim=1).type(y.dtype) == y)\n            acc_t += torch.sum(outputs_teacher.argmax(dim=1).type(y.dtype) == y)\n        scheduler.step()\n        losses.append(loss_sum.cpu().detach().numpy() / len(train_loader))\n        print( \"epoch: \", i, \"loss=\", loss_sum.item(), \"训练集准确度=\",(acc/(len(train_loader)*train_loader.batch_size)).item(),end=\"\")\n        print( \"epoch: \", i, \"loss=\", loss_sum.item(), \"teacher准确度=\",(acc_t/(len(train_loader)*train_loader.batch_size)).item(),end=\"\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:24.847933Z","iopub.execute_input":"2024-04-11T15:47:24.848318Z","iopub.status.idle":"2024-04-11T15:47:24.861897Z","shell.execute_reply.started":"2024-04-11T15:47:24.848277Z","shell.execute_reply":"2024-04-11T15:47:24.860967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts,ExponentialLR\n\nprint(train_images.shape)\nprint(train_labels.shape)\nprint(validation_images.shape)\nvalidation_labels = np.array(validation_labels)\nprint(validation_labels.shape)\n\n#train_dataset = ImageDataset(train_images, train_labels, transform=transforms_train)\ntrain_dataset = ImageDataset(train_images, train_labels, transform=transforms_train)\nvalidation_dataset = ImageDataset(validation_images, validation_labels, transform=transforms_test)\n#submit_ds = ImageDataset(csv_file='/kaggle/input/classify-leaves/test.csv', root_dir='../input/classify-leaves', transform=transforms_test, label_return=False)\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=False)\nvalidation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False, drop_last=False)\n#submit_loader = DataLoader(submit_ds, batch_size=32, shuffle=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:25.288733Z","iopub.execute_input":"2024-04-11T15:47:25.289106Z","iopub.status.idle":"2024-04-11T15:47:25.297993Z","shell.execute_reply.started":"2024-04-11T15:47:25.289077Z","shell.execute_reply":"2024-04-11T15:47:25.296963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch = 40\ntrain_parent(train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:25.960294Z","iopub.execute_input":"2024-04-11T15:47:25.961364Z","iopub.status.idle":"2024-04-11T15:47:29.404872Z","shell.execute_reply.started":"2024-04-11T15:47:25.961328Z","shell.execute_reply":"2024-04-11T15:47:29.403642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch = 80\nteach_student(train_loader)\n#net = parent\n#train_model(train_loader,validation_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:31.678155Z","iopub.execute_input":"2024-04-11T15:47:31.678921Z","iopub.status.idle":"2024-04-11T15:47:34.817061Z","shell.execute_reply.started":"2024-04-11T15:47:31.678881Z","shell.execute_reply":"2024-04-11T15:47:34.815853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch = 70\ntrain_model_with_teacher(train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:38.038236Z","iopub.execute_input":"2024-04-11T15:47:38.038920Z","iopub.status.idle":"2024-04-11T15:47:43.859976Z","shell.execute_reply.started":"2024-04-11T15:47:38.038886Z","shell.execute_reply":"2024-04-11T15:47:43.858600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nclass ImageDatasetWithoutLabels(Dataset):\n    \"\"\"A dataset class for images without labels.\"\"\"\n    def __init__(self, images, transform=None):\n        self.images = images\n        self.transform = transform\n\n        \n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        if self.transform:\n            image = self.transform(image=image)['image']\n        return image\n    \nsubmit_dataset = ImageDatasetWithoutLabels(images, transform=transforms_test)\nsubmit_loader = DataLoader(submit_dataset, batch_size=64, shuffle=False, drop_last=False)\nnet.eval()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnet.to(device)\n\npredictions = []\n\n# Disable gradient computation for evaluation\nwith torch.no_grad():\n    for inputs in submit_loader:\n        inputs = inputs.to(device)  # Move the inputs to the same device as the model\n        outputs = net(inputs)\n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n        \n# Assuming the ID is just the index of the image\nsubmission_df = pd.DataFrame({\n    'ID': np.arange(len(predictions)),\n    'Labels': predictions\n})\n\n# Write the submission file\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:47:47.249110Z","iopub.execute_input":"2024-04-11T15:47:47.249854Z","iopub.status.idle":"2024-04-11T15:47:51.590791Z","shell.execute_reply.started":"2024-04-11T15:47:47.249818Z","shell.execute_reply":"2024-04-11T15:47:51.589703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission_df","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:46:47.555998Z","iopub.status.idle":"2024-04-11T15:46:47.556653Z","shell.execute_reply.started":"2024-04-11T15:46:47.556463Z","shell.execute_reply":"2024-04-11T15:46:47.556481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}